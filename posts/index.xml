<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Nok</title>
    <link>https://nok3zy.github.io/posts/</link>
    <description>Recent content in Posts on Nok</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 22 Aug 2023 15:13:11 +0900</lastBuildDate><atom:link href="https://nok3zy.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Java Async Programming</title>
      <link>https://nok3zy.github.io/posts/java-async-programming/</link>
      <pubDate>Tue, 22 Aug 2023 15:13:11 +0900</pubDate>
      
      <guid>https://nok3zy.github.io/posts/java-async-programming/</guid>
      <description>자바에서 아래와 같이 두 개의 서비스에 요청을 보내고 그 결과가 오면 처리를 해야하는 로직이 있다면 어떻게 수행할까?
User user = userService.callGetUser(); Account account = accountService.callGetAccount(); Finance finance = Finance.of(user,account); return finance; 당연히 차례대로 진행한다. user 정보를 얻고, account 정보를 얻고 Finance 객체를 만들어서 반환한다. 로직만으로 보면 문제되는 것이 없어보인다.
하지만 그 과정에서 쓰레드의 Idling이 문제가 된다.
서버의 쓰레드는 Client에게 Request가 오면 그에 대한 응답값을 내려주기 위해 작업을 수행한다. 하나의 쓰레드가 응답값을 구할 때까지 계속 책임감있게 작업을 잡고 있는다.</description>
    </item>
    
    <item>
      <title>DB ConnectionPool</title>
      <link>https://nok3zy.github.io/posts/db-connectionpool/</link>
      <pubDate>Thu, 10 Aug 2023 21:12:18 +0900</pubDate>
      
      <guid>https://nok3zy.github.io/posts/db-connectionpool/</guid>
      <description>DB와 어플리케이션 간 통신을 하기 위한 연결점을 Connection이라 한다. 그리고 이를 미리 여러개를 만들어 놓은 것을 Connection Pool이라고 한다.
Connection을 미리 만들어 놓는 이유는 서버와 DB를 연결할 때 드는 비용이 많이 들기 때문이다.
TCP 와 ConnectionPool 🔗DBMS와의 통신은 TCP로 이루어진다. 네트워크에 대해 공부했다면, 많이들 TCP와 UDP에 대해서 많이 들어봤을 것이다.
TCP는 흔히들 신뢰성이 있다고 말하는데, 그 이유는 3-way handshake 과정을 통해 연결성을 보장한 통신을 시작하기 때문이다. TCP는 자신이 보낸 데이터에 대해 상대방이 받았다는 의미의 응답 패킷을 다시 받아야 통신이 정상적으로 이루어졌다고 생각한다.</description>
    </item>
    
    <item>
      <title>Why Kafka is fast</title>
      <link>https://nok3zy.github.io/posts/why-kafka-is-fast/</link>
      <pubDate>Wed, 09 Aug 2023 19:14:18 +0900</pubDate>
      
      <guid>https://nok3zy.github.io/posts/why-kafka-is-fast/</guid>
      <description>카프카는 디스크를 사용하는데 어떻게 빠를까?
근데 빠르다는 것은 좀 모호한 것 같다. 레이턴시가 짧다는 걸까? 처리량이 많다는 걸까? 카프카는 대용량 데이터를 처리하는 것을 최적화했다.
사람들이 카프카가 빠르다고 하는 의미는, 보통 카프카가 큰 데이터를 효율적으로 옮기는 능력이 좋다는 것을 의미한다.
카프카의 성능이 좋은 이유에는 많은 요소가 있겠지만, Sequential IO 와 Zero Copy , 이 두 가지가 큰 이점을 제공한다.
Sequential IO 🔗일반적으로 디스크에 접근하는 것이 메모리 접근보다 느린 것은 맞다. 하지만 디스크가 느린 이유는 바로 data-access 방식의 문제이다.</description>
    </item>
    
    <item>
      <title>Thread In Java</title>
      <link>https://nok3zy.github.io/posts/thread-in-java/</link>
      <pubDate>Mon, 07 Aug 2023 15:45:18 +0900</pubDate>
      
      <guid>https://nok3zy.github.io/posts/thread-in-java/</guid>
      <description>&amp;ldquo;프로세스와 쓰레드의 차이를 아세요?&amp;rdquo;
흔히 듣는 질문이다. 중요하니깐 많이들 물어보는 것이겠지만, 가끔 갑자기 물어보면 제대로 대답하기가 어려운 질문이기도 하다.
프로세스는 실행된 프로그램의 인스턴스이다. 그리고 쓰레드는 프로세스 내의 실행 단위이다. 프로세스 내부에 쓰레드가 존재한다.
둘의 차이는 쓰레드의 특성을 생각해보면 쉽다. 쓰레드는 프로세스 내에서 Code, Data, Heap을 쓰레드끼리 공유한다. 그리고 각 쓰레드는 각자의 Stack은 따로 가지고 있는다.
반면, 프로세스는 Code,Data,Heap, Stack 을 다른 프로세스와 공유하지 않는다. 이것이 멀티 프로세스보다 멀티 쓰레드가 효율적인 이유다.</description>
    </item>
    
    <item>
      <title>Java GC</title>
      <link>https://nok3zy.github.io/posts/java-gc/</link>
      <pubDate>Sat, 05 Aug 2023 20:49:40 +0900</pubDate>
      
      <guid>https://nok3zy.github.io/posts/java-gc/</guid>
      <description>GC(Garbage Collecotor)는 사용하지 않는 메모리들을 정리해준다. JVM에서도 GC를 통해서 사용하지 않는 메모리들을 다시 사용가능한 상태로 만든다. 이것이 어떻게 동작하는 지 알기 위해서는 먼저 JVM의 메모리 구조를 알아야한다.
JVM Memory 🔗 JVM Memory 구조는 위의 사진처럼 5개의 영역으로 구분할 수 있다.
Method와 Heap은 모든 쓰레드가 공유하는 영역이고, 나머지 Stack, PC Register, Native Method Stack은 각 쓰레드가 하나씩 부여받는다.
Method Class, Interface, Method, field, Static variable 등이 저장되는 영역.
Heap new 키워드로 생성되는 객체(혹은 배열)이 저장되는 영역.</description>
    </item>
    
    <item>
      <title>Optimize API</title>
      <link>https://nok3zy.github.io/posts/optimize-api/</link>
      <pubDate>Sat, 22 Jul 2023 17:50:41 +0900</pubDate>
      
      <guid>https://nok3zy.github.io/posts/optimize-api/</guid>
      <description>MongoRepository(혹은 JpaRepository)같은 ORM 인터페이스를 통해서 Entity를 조회했을 때, 어떻게 쿼리를 보낼까?
처음에는 DB.Collection.findOne() 혹은 Select * from Table LIMIT 1 정도의 쿼리를 보내지 않을까? 이지 않을까 추측했다. 테이블(혹은 도큐먼트)의 모든 필드를 가져와서 내부적으로 맵핑을 하지 않을까 싶었다. JPA는 내부적으로 Mapper가 존재해서 Document to Object로 변경해주는 작업을 하고 있는 걸로 아는데, 그렇다면 모든 필드를 조회하고, 코드에서 필드로 명시된 경우에만 맵핑을 해주는 것은 아닐까?
아래의 경우에는 어떻게 찾을까?
//Product Java Code Product{ id name } //Product Collecion Product{ id name price description } Java code에서는 Product의 seller라는 필드를 포함하고 있지 않는다.</description>
    </item>
    
    <item>
      <title>Gateway</title>
      <link>https://nok3zy.github.io/posts/gateway/</link>
      <pubDate>Thu, 06 Jul 2023 22:57:22 +0900</pubDate>
      
      <guid>https://nok3zy.github.io/posts/gateway/</guid>
      <description>트래픽이 적고 서버가 작다면 위와 같이 Client에 Server에 직접 요청을 보내도 큰 문제가 생기지 않는다.
하지만 트래픽이 많아져서 서버를 늘리게 되었고 각 서버들이 공통된 로직을 처리해야한다면 문제가 발생한다.
이런 모양의 아키텍처가 구성되었을 때, 각 서버 담당자는 Auth 서버에 대한 릴리즈를 모두 파악하고 있어야 한다. 만약에 업데이트를 한번 놓치면 어떤 오류가 발생할지 모른다. 따라서 이는 꽤나 비효율적인 구조라고 할 수 있다.
그렇다면 앞에 공통 로직을 수행하는 서버를 하나 두는 것은 어떨까?</description>
    </item>
    
    <item>
      <title>MSA Observility</title>
      <link>https://nok3zy.github.io/posts/msa-observility/</link>
      <pubDate>Wed, 28 Jun 2023 19:44:37 +0900</pubDate>
      
      <guid>https://nok3zy.github.io/posts/msa-observility/</guid>
      <description>시스템의 출력으로 부터 상태를 이해할 수 있는 능력을 Observility 라고 한다. 다시 말하자면, 로그나 실시간으로 수집되는 모니터링 지표같은 출력을 통해 시스템의 상태를 이해할 수 있는 능력을 의미한다.
이 글은 토스 SLASH23을 보고 정리한 내용입니다.
MSA 환경에서의 모니터링 🔗클라우드, MSA 아키텍처 등은 기존의 IT 시스템이 가지고 있던 문제들을 개선하며, 민첩한 개발을 할 수 있게 한다. 이 기술들은 기술의 기반환경을 가상화, 추상화를 통해 기존의 문제들을 해결하는데 도움을 주고 있다.
과연 클라우드와 MSA 아키텍처가 장점만 있는 것일까?</description>
    </item>
    
    <item>
      <title>Mongo Custom Converter</title>
      <link>https://nok3zy.github.io/posts/mongo-custom-converter/</link>
      <pubDate>Tue, 13 Jun 2023 17:36:18 +0900</pubDate>
      
      <guid>https://nok3zy.github.io/posts/mongo-custom-converter/</guid>
      <description>Dynamic Creative 에서 상품 데이터를 Catalog로 만들면서, Document에 존재하는 국제화 데이터를 가공할 필요가 있었다. 상품의 Title이나 Description 등의 정보들이 있었고, 또한 해당 국가에서 접근이 가능한 상품인지 아닌지 등을 따져야하는 경우가 있었다.
여기서 생긴 문제는 필요한 데이터의 키값이 다르게 설정되어 있었다는 것이다.
Title { KR : &amp;#34;커피&amp;#34;, US : &amp;#34;Coffee&amp;#34;, JP : &amp;#34;コーヒー&amp;#34; } Description { ko : &amp;#34;안녕하세요&amp;#34;, en : &amp;#34;Hello&amp;#34;, ja : &amp;#34;こんにちは&amp;#34; } 이런 식으로 각 국가마다 노출해줄 데이터의 키값이 달랐다.</description>
    </item>
    
    <item>
      <title>Upload updated catalog every N hours</title>
      <link>https://nok3zy.github.io/posts/upload-updated-catalog-every-n-hours/</link>
      <pubDate>Fri, 26 May 2023 16:32:39 +0900</pubDate>
      
      <guid>https://nok3zy.github.io/posts/upload-updated-catalog-every-n-hours/</guid>
      <description>Dynamic Creative 프로젝트를 진행하면서, 업데이트가 되는 상품 정보를 모델에 적용시킬 수 있도록 해당 정보들을 올려달라는 요구사항을 받았다. 상품 정보는 업데이트가 정말 많이 일어나는 collection이었다. 그래서 번경이 일어나는 곳에서 이벤트를 감지해서 하기는 무리가 있었고 더군다나 여러 MSA에서 사용하고 있었기 때문에 더 말이 되지 않았다.
ChangeStream 🔗결국 선택한 방법은 Mongo의 ChangeStream을 이용하는 것이었다. 그리고 Spring MongoTemplate을 이용해서, 아래와 같이 ChangeStream에 접근할 수 있었다.
final MongoCollection&amp;lt;Document&amp;gt; collection = mongoTemplate.getCollection(COLLECTION_NAME); final ChangeStreamIterable&amp;lt;Document&amp;gt; changeStream = collection.</description>
    </item>
    
    <item>
      <title>Helm Release</title>
      <link>https://nok3zy.github.io/posts/helm-release/</link>
      <pubDate>Thu, 18 May 2023 18:34:16 +0900</pubDate>
      
      <guid>https://nok3zy.github.io/posts/helm-release/</guid>
      <description>하나의 서비스를 위해 k8s의 여러 자원들이 존재한다. 예를 들어, service, serviceAccount, ingress 등이 있다. 그리고 이런 자원들을 정리하는 것이 helm release이다. helm의 release는 여러 쿠버네티스 상의 자원들을 관리해주며, Release를 uninstall을 하면 위 자원들도 같이 제거된다. 따라서 기존에 존재하는 모든 녀석들을 이와 같이 제거해주고 Release를 만들때 다 같이 만든다.
kubectl을 이용해서 배포하는 서비스의 경우, release가 관리가 되지 않아서 필요가 없어지는 경우에는 매번 손으로 제거해줘야 하는 귀찮음이 존재했다.
그래서 helm upgrade로 배포할 수 있도록 변경했더니 resource conflict 오류가 발생했다.</description>
    </item>
    
    <item>
      <title>K8s memory, cpu setting</title>
      <link>https://nok3zy.github.io/posts/k8s-memory-cpu-setting/</link>
      <pubDate>Sun, 07 May 2023 16:14:25 +0900</pubDate>
      
      <guid>https://nok3zy.github.io/posts/k8s-memory-cpu-setting/</guid>
      <description>이 글은 Natan Yellin at Robusta의 k8s memory limit, cpu-limit을 읽고 정리한 글입니다.
CPU 🔗많은 사람들이 K8s에서 CPU limit이 필요하다고 하는데 그렇지 않습니다. 대부분의 상황에서 cpu limit은 오히려 해롭습니다.
왜 CPU limit이 해로운지 비유로 설명하겠습니다. CPU는 물, CPU starvation은 죽음입니다. CPU와 마찬가지로 이 이야기에서의 물은 재생 가능한 자원입니다. 간단히 말해, 특정 순간에 CPU 사용량이 100% 라고 해서 완전히 소모되지 않는 다는 것입니다. CPU는 항상 재생합니다.
이 이야기에서 사람은 사막에서 하루에 1 리터가 필요합니다.</description>
    </item>
    
    <item>
      <title>Build Version</title>
      <link>https://nok3zy.github.io/posts/build-version/</link>
      <pubDate>Fri, 21 Apr 2023 22:04:13 +0900</pubDate>
      
      <guid>https://nok3zy.github.io/posts/build-version/</guid>
      <description>내가 구성한 파이프라인에서 발생했던 문제는 빌드가 되었을 때, 항상 다른 버전으로 빌드가 된다는 것이었다. 다르게 표현하자면, 같은 코드가 빌드시 다른 빌드 Id를 가지는 것이 문제였다. 왜 문제였을까?
Static file 🔗빌드마다 다른 아이디값이 문제가 되는 이유는 스태틱파일 때문이었다. JS, Image 와 같은 정적 파일들은 미리 CDN에 올려놓게 되는데, 이 과정에서 문제가 생겼다. 빌드가 될때 기존과 다른 아이디를 이용하게 되면서, 똑같은 파일에서 빌드를 두번 시행할 경우에 스태틱 파일이 두개가 생기게 된다. 그러면 어떤 스태틱파일을 사용해야할지 알 수 있을까?</description>
    </item>
    
    <item>
      <title>Let&#39;s use Kafka</title>
      <link>https://nok3zy.github.io/posts/lets-use-kafka/</link>
      <pubDate>Sun, 02 Apr 2023 19:18:02 +0900</pubDate>
      
      <guid>https://nok3zy.github.io/posts/lets-use-kafka/</guid>
      <description>서비스 내에서 주기적으로 유저의 상황을 판단하기 위해, 유저 당 10초마다 GraphQL를 보내고 있었다. 이 과정에서, 쿼리 비용이 굉장히 많이 나왔고 이를 개선하기로 결정했다.
어떻게 해결할 수 있을까 고민하다가, 기존에 활용되던 카프카 토픽에 이미 필요한 데이터가 쌓이는 데이터가 있는 것을 확인했다. 그래서 GraphQL로 보내던 요청을 이 카프카 토픽을 이용해서 해결하기로 결정했다.
GraphQL이 Apollo Server를 거치면서 비용이 발생했고, 이 방식을 이용하면 RestApi를 통해서 쌓이는 이벤트이다보니 문제를 해결할 수 있어보였다.
Consumer Group 🔗기존에 사용하던 토픽을 이용하기로 했고, 필요한 것은 기존 기능을 해치지 않는 것이었다.</description>
    </item>
    
    <item>
      <title>How to test</title>
      <link>https://nok3zy.github.io/posts/how-to-test/</link>
      <pubDate>Sun, 26 Mar 2023 14:40:02 +0900</pubDate>
      
      <guid>https://nok3zy.github.io/posts/how-to-test/</guid>
      <description>테스트 🔗프로젝트를 진행하다보면, 테스트를 굉장히 많이 작성하게 된다. 가끔은 비지니스 로직보다 테스트를 위한 코드가 더 많이 나오는 경우도 있다.
과연 기능 개발에 드는 시간과 테스트에 드는 시간만큼 혹은 그 이상을 소비하는 것이 옳은 일일까? 개인적으로는 테스트에 투자하는 것이 개발자의 생산성을 향상시킨다고 생각한다.
개인적으로 느낀 테스트의 장점은 다음과 같다.
레거시 코드를 리팩토링하는 경우에 테스트만큼 좋은 방향성 지표가 없다. 효율이 좋지 않거나, 여러 이유로 코드를 변경하게 되는 경우 이만큼 마음을 안정시켜주는 것이 없다.</description>
    </item>
    
    <item>
      <title>CICD Pipeline Migration</title>
      <link>https://nok3zy.github.io/posts/cicd-pipeline-migration/</link>
      <pubDate>Sat, 25 Feb 2023 18:51:21 +0900</pubDate>
      
      <guid>https://nok3zy.github.io/posts/cicd-pipeline-migration/</guid>
      <description>Harness를 CICD 파이프라인 구축하면서 있었던 일들을 정리해본다.
CICD 파이프라인을 구축해보면서 고민했던 내용을 정리하는 느낌으로 작성하는 것이므로 하네스와 관련된 것은 최대한 제외했다.
CICD가 무엇일까 파이프라인 구성하기 인프라 요구사항 파이프라인 만들기 CICD가 무엇일까 🔗CICD Pipeline을 새로 구축하면서,CICD라는 의미를 알고는 있지만 정확히 몰랐다. 그냥 뭐 테스트하고 자동으로 배포하고 그런것이 아닐까?
CI(Continuous Integration)은 어플리케이션에 적용한 사항이 병합되었을 때, 자동으로 테스트하면서 잘 적용되었는지를 확인하는 작업을 자동화한 것을 의미한다. 간단히 말해서, 기존코드와 신규코드에 충돌이 있는지 확인하는 과정이라고 생각하면 될 것 같다.</description>
    </item>
    
    <item>
      <title>Improve spring test</title>
      <link>https://nok3zy.github.io/posts/improve-spring-test/</link>
      <pubDate>Sun, 22 Jan 2023 22:32:19 +0900</pubDate>
      
      <guid>https://nok3zy.github.io/posts/improve-spring-test/</guid>
      <description>기능을 개발하면서 제대로 동작하는 지는 테스트를 돌리면서 확인해야 한다. 단위테스트가 제대로 동작하는 것을 확인하고, 스테이징 환경에서도 의도된 대로 동작하는 것을 확인하고 깃에 푸시를 한다. 푸시를 하면 정해진 액션대로 CI를 기다려야 했다. 프로젝트에서 관리중인 코드가 굉장히 많기 때문에, 테스트 시간도 그에 비례해서 오래 걸릴 수 밖에 없었다. 그런데 이 시간이 생산성을 잡아먹는다고 생각이 들었다. 아 너무 오래걸리는데?
이미 KTLO list에도 레거시 모듈 청산이 있었기 때문에, 레거시부터 정리해나가야 겠다고 생각했다. 그래 필요없는 코드를 제거해보자.</description>
    </item>
    
    <item>
      <title>System Architecture</title>
      <link>https://nok3zy.github.io/posts/system-architecture/</link>
      <pubDate>Sat, 21 Jan 2023 20:59:03 +0900</pubDate>
      
      <guid>https://nok3zy.github.io/posts/system-architecture/</guid>
      <description>한 프로젝트를 처음부터 시작하면서 선택을 해야하는 순간이 많았다. 종종 어떤 것을 선택하시겠어요?라는 선택지가 나에게 주어졌고 나는 어리둥절하며 고민을 해야 했다. 어떤 것이 좋은 거지? 무엇이 옳은 거지?
그런 선택지들을 고르기 위해서는 시스템 아키텍처에 대한 이해가 필요했다. 그리고 전반적인 상황을 이해하기 위해서라도 공부를 해야만 했다.
좋은 인프라는 무엇일까 🔗질문에 대한 답은 명백하다. 장애에 대해 Robust하고 확장이 쉽고 관측도 편하며 비용이 적게드는 것이 가장 좋은 인프라이다. 하지만 그런 인프라는 존재하지 않는다. 비용을 많이 투자해야 성능이 좋게 나오는 법이다.</description>
    </item>
    
    <item>
      <title>Clean Architecture</title>
      <link>https://nok3zy.github.io/posts/clean-architecture/</link>
      <pubDate>Sun, 15 Jan 2023 21:49:24 +0900</pubDate>
      
      <guid>https://nok3zy.github.io/posts/clean-architecture/</guid>
      <description>클린 아키텍처가 뭐죠 🔗내가 클린 아키텍처를 고민해보기 시작한 것은 다른 팀으로 이동하고 나서부터다. 팀을 이동하면서 앞으로 내가 할 프로젝트의 첫 인상은 개발 언어도, 도메인도 다르고 멀티 모듈로 둘러쌓여 굉장히 복잡해 보였다. (물론 레거시도 많아서 더 복잡해보였다.)
&amp;ldquo;이 아키텍처는 클린 아키텍처에 기반해서 만들었어요.&amp;rdquo;
그 말에 바로 클린 아키텍처부터 읽었다. 이 구조를 이해하는 데 도움이 될 것이라고 생각했다. 그리고 좋은 책이라고 많이 들었기 때문에 고민없이 책을 읽게 되었다. 책에 적힌 모든 걸 한번에 이해할 수는 없었지만, 어떤 것을 말하고 싶은지는 이해를 할 수 있었다.</description>
    </item>
    
    <item>
      <title>2022년 회고</title>
      <link>https://nok3zy.github.io/posts/2022%EB%85%84-%ED%9A%8C%EA%B3%A0/</link>
      <pubDate>Sun, 01 Jan 2023 01:13:08 +0900</pubDate>
      
      <guid>https://nok3zy.github.io/posts/2022%EB%85%84-%ED%9A%8C%EA%B3%A0/</guid>
      <description>1. 개발자가 되었다. 🔗취업을 준비하면서 과연 내가 개발을 할 수 있을까 하는 생각에서 벗어날 수 없었다. 무엇을 공부해야 하는지, 준비해야하는 지 알고 있었지만 항상 부족하다고 느꼈다. 흔히들 말하는 코딩테스트와 프로젝트을 준비했지만 그렇게 경쟁력이 있다고 느껴지진 않았다.
코딩테스트를 준비하기로 한 첫번째 달에 매일 3문제씩 풀어서 한 달만에 100문제를 풀었다. 그리고 매일 적어도 한문제씩 1년을 풀었다. 그렇게 풀다보니 어떤 코딩테스트를 봐도 통과할 정도는 되었다.
하지만 문제는 프로젝트였다. 프로젝트를 한다고 했는데 어떻게 준비해야할지 몰랐고 한다고 했던 것들은 정말 봐주기 어려울 정도였다.</description>
    </item>
    
  </channel>
</rss>
